/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_0.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_0 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_1.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_1 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_2.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_2 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_3.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_3 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_4.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_4 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_5.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_5 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_6.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_6 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_7.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_7 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_8.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_8 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_0.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_0 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_1.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_1 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_2.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_2 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_3.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_3 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_4.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_4 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_5.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_5 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_6.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_6 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_7.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_7 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB256BL384_8.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB256BL384_8 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_0.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_0 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_1.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_1 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_2.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_2 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_3.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_3 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_4.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_4 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_5.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_5 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_6.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_6 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB128BL256_7.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB128BL256_7 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_BL128_0.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_BL128_0 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_BL128_1.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_BL128_1 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_BL128_2.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_BL128_2 --dataset-impl mmap --workers 48
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_BL128_3.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_BL128_3 --dataset-impl mmap --workers 48
