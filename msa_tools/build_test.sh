/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_0_0.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_0_0 --dataset-impl mmap --workers 50
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_0_1.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_0_1 --dataset-impl mmap --workers 50
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_0_2.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_0_2 --dataset-impl mmap --workers 50
/opt/conda/bin/python ../tools/preprocess_data.py --input /dataset/ee84df8b/data/JSON/MSA_AB384BL512_0_3.json             --tokenizer-type BertWordPieceCase --vocab-file ./msa_vocab.txt             --output-prefix /dataset/ee84df8b/data/BIN/MSA_AB384BL512_0_3 --dataset-impl mmap --workers 50
